{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bioimage Quality Control (QC) Notebook\n",
    "\n",
    "This notebook provides a set of simple quality control analyses for microscopy images, allowing users to flag issues such as saturation, crosstalk or inappropriate bit depth.\n",
    "\n",
    "**QC checks implemented:**\n",
    "- Histogram oddities\n",
    "- Background flatness\n",
    "- Bit depth assessment\n",
    "- Dynamic range calculation\n",
    "- Saturation percentage\n",
    "\n",
    "⚠️ **WORK IN PROGRESS** The code is based on a prototype script. "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T18:43:16.821435Z",
     "start_time": "2025-08-21T18:43:16.815603Z"
    }
   },
   "source": [
    "import bioio_ome_tiff\n",
    "import numpy as np\n",
    "from bioio import BioImage\n",
    "from scipy.optimize import curve_fit\n",
    "from skimage.transform import resize\n",
    "\n",
    "from regression_model import *\n",
    "from regression_model import CrossTalkRegressionModel"
   ],
   "outputs": [],
   "execution_count": 38
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detect Odd Histogram Distribution\n",
    "Flags images with strange histogram distributions (e.g., many zero bins within the main intensity range)."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T18:43:16.883838Z",
     "start_time": "2025-08-21T18:43:16.872253Z"
    }
   },
   "source": [
    "def detect_odd_histogram_distribution(image, bins=256, percentile_threshold=99.99):\n",
    "    # Calculate the histogram of the image\n",
    "    hist, bin_edges = np.histogram(image, bins=bins, range=(np.min(image), np.max(image)))\n",
    "\n",
    "    # Calculate the cumulative histogram to find the percentile threshold bin\n",
    "    cumulative_hist = np.cumsum(hist)\n",
    "    total_pixels = cumulative_hist[-1]\n",
    "\n",
    "    # Find the bin that corresponds to the 95th percentile\n",
    "    threshold_index = np.searchsorted(cumulative_hist, percentile_threshold / 100 * total_pixels)\n",
    "\n",
    "    # Find the indices of the first non-zero bin\n",
    "    non_zero_bins = np.where(hist > 0)[0]\n",
    "    if len(non_zero_bins) == 0:\n",
    "        # If no non-zero bins are found return zero for all metrics\n",
    "        return 0, 0\n",
    "\n",
    "    first_non_zero_bin = non_zero_bins[0]\n",
    "\n",
    "    # Count zero bins between the first non-zero bin and the threshold bin\n",
    "    zero_bins = np.sum(hist[first_non_zero_bin:threshold_index] == 0)\n",
    "\n",
    "    # Calculate the ratio of zero bins to the total number of bins in this range\n",
    "    total_bins_in_range = threshold_index - first_non_zero_bin\n",
    "    zero_bin_ratio = zero_bins / total_bins_in_range if total_bins_in_range > 0 else 0\n",
    "\n",
    "    return zero_bins, zero_bin_ratio"
   ],
   "outputs": [],
   "execution_count": 39
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimate Background Flatness\n",
    "Fits a flat plane to each slice of a 3D image and measures deviation for non-uniformity."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T18:43:16.931355Z",
     "start_time": "2025-08-21T18:43:16.916281Z"
    }
   },
   "source": [
    "def flat_plane(coords, p0, p1, p2):\n",
    "    # Unpack the coordinates\n",
    "    x, y = coords\n",
    "    # Linear plane model (1st order polynomial)\n",
    "    return p0 * x + p1 * y + p2\n",
    "\n",
    "\n",
    "def estimate_background_flat_plane_deviation(image_3d):\n",
    "    depth, height, width = image_3d.shape\n",
    "\n",
    "    # Initialize array to store background estimates for each slice\n",
    "    background_3d = np.zeros_like(image_3d, dtype=np.float64)\n",
    "\n",
    "    deviations = []\n",
    "\n",
    "    for z in range(depth):\n",
    "        print(f'Checking slice {z} of {depth}')\n",
    "        # Process each 2D slice independently\n",
    "        image = image_3d[z, :, :]\n",
    "\n",
    "        # Generate grid of coordinates\n",
    "        y = np.arange(height)\n",
    "        x = np.arange(width)\n",
    "        xx, yy = np.meshgrid(x, y)\n",
    "\n",
    "        # Flatten arrays\n",
    "        x_flat = xx.ravel()\n",
    "        y_flat = yy.ravel()\n",
    "        image_flat = image.ravel()\n",
    "\n",
    "        # Fit a flat plane to the current slice\n",
    "        p_initial = np.zeros(3)\n",
    "        params, _ = curve_fit(flat_plane, (x_flat, y_flat), image_flat, p0=p_initial)\n",
    "\n",
    "        # Calculate fitted background for the current slice\n",
    "        background_slice = flat_plane((xx, yy), *params).reshape(image.shape)\n",
    "\n",
    "        # Store the fitted background slice in the 3D array\n",
    "        background_3d[z, :, :] = background_slice\n",
    "\n",
    "        # Calculate deviation from the flat plane\n",
    "        deviation = np.abs(image - background_slice)\n",
    "        deviations.append(np.std(deviation))\n",
    "\n",
    "    # The non-uniformity metric could be an average or max deviation across slices\n",
    "    non_uniformity = np.mean(deviations)  # or max(deviations)\n",
    "\n",
    "    return background_3d, non_uniformity"
   ],
   "outputs": [],
   "execution_count": 40
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bit Depth Checker\n",
    "Warns if the image bit depth is unusually low."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T18:43:16.964054Z",
     "start_time": "2025-08-21T18:43:16.956224Z"
    }
   },
   "source": [
    "def check_bit_depth(image):\n",
    "    # Determine the bit depth of the image\n",
    "    bit_depth = image.dtype.itemsize * 8  # itemsize gives the number of bytes, so multiply by 8 to get bits\n",
    "\n",
    "    if bit_depth <= 8:\n",
    "        print(f\"Warning: The image has a low bit depth of {bit_depth}-bits, which may limit image quality.\")\n",
    "    else:\n",
    "        print(f\"The image has a bit depth of {bit_depth}-bits, which is adequate for most purposes.\")\n",
    "\n",
    "    return bit_depth"
   ],
   "outputs": [],
   "execution_count": 41
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dynamic Range Calculation"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T18:43:16.989496Z",
     "start_time": "2025-08-21T18:43:16.981422Z"
    }
   },
   "source": [
    "def calculate_dynamic_range(image):\n",
    "    min_intensity = np.min(image)\n",
    "    max_intensity = np.max(image)\n",
    "\n",
    "    # Determine the maximum possible range based on the image's data type\n",
    "    dtype_max = np.iinfo(image.dtype).max\n",
    "\n",
    "    # Normalized dynamic range\n",
    "    dynamic_range = (max_intensity - min_intensity) / dtype_max\n",
    "    return dynamic_range"
   ],
   "outputs": [],
   "execution_count": 42
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saturation Percentage\n",
    "Calculates percentage of pixels that are fully saturated (min or max value for the data type)."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T18:43:17.020771Z",
     "start_time": "2025-08-21T18:43:17.015176Z"
    }
   },
   "source": [
    "def calculate_saturation_percentage(image):\n",
    "    # Determine the minimum and maximum possible values based on the image's data type \n",
    "    dtype_min = np.iinfo(image.dtype).min\n",
    "    dtype_max = np.iinfo(image.dtype).max\n",
    "\n",
    "    # Count the number of saturated pixels\n",
    "    saturated_pixels = np.sum((image == dtype_min) | (image == dtype_max))\n",
    "\n",
    "    # Calculate the total number of pixels\n",
    "    total_pixels = image.size\n",
    "\n",
    "    # Calculate the percentage of saturated pixels\n",
    "    saturation_percentage = (saturated_pixels / total_pixels) * 100\n",
    "\n",
    "    return saturation_percentage"
   ],
   "outputs": [],
   "execution_count": 43
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Estimate Cross-talk"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T18:43:17.042110Z",
     "start_time": "2025-08-21T18:43:17.033170Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def normalize_image(img):\n",
    "    img_min, img_max = img.min(), img.max()\n",
    "    if img_max > img_min:  # Avoid division by zero\n",
    "        return (img - img_min) / (img_max - img_min)\n",
    "    else:\n",
    "        return img\n",
    "\n",
    "\n",
    "def crosstalk_test_transforms_fn(mixed_np, source_np):\n",
    "    mixed_np = normalize_image(resize(mixed_np.astype(np.float32), (256, 256)))\n",
    "    source_np = normalize_image(resize(source_np.astype(np.float32), (256, 256)))\n",
    "    mixed_tensor = torch.from_numpy(mixed_np).unsqueeze(0)\n",
    "    source_tensor = torch.from_numpy(source_np).unsqueeze(0)\n",
    "\n",
    "    return torch.cat([mixed_tensor, source_tensor], dim=0).unsqueeze(0)\n",
    "\n",
    "\n",
    "def estimate_crosstalk(channel1, channel2):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "    crosstalk_model = CrossTalkRegressionModel(initial_filters=128, num_conv_blocks=6)\n",
    "    crosstalk_model.load_state_dict(\n",
    "        torch.load('./crosstalk_model/crosstalk_regression_model_trained_2025-08-21_01-02-53_256_0.0005.pth',\n",
    "                   map_location=device))\n",
    "    crosstalk_model.eval()\n",
    "    crosstalk_model.to(device)\n",
    "    # Wrap the prediction in the no_grad context\n",
    "    with torch.no_grad():\n",
    "        # 1. Convert the NumPy array to a PyTorch tensor\n",
    "        input_tensor = crosstalk_test_transforms_fn(channel1, channel2)\n",
    "\n",
    "        # 2. Move the tensor to the correct device\n",
    "        input_tensor = input_tensor.to(device)\n",
    "\n",
    "        # 3. Make a single prediction\n",
    "        output = crosstalk_model(input_tensor)\n",
    "\n",
    "        # 4. Get the predicted labels and convert to NumPy\n",
    "        # For a classification model, you might use argmax to get the class index\n",
    "        #predicted_label = torch.argmax(output, dim=1).item()\n",
    "\n",
    "        # If your model's output is not a class, you can just\n",
    "        # move it to the CPU and convert to a NumPy array.\n",
    "        return output[0].cpu().numpy()[0]"
   ],
   "outputs": [],
   "execution_count": 44
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Usage\n",
    "\n",
    "This block demonstrates how to use the QC functions on an example image. Replace the image path with your own image as needed."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T18:53:42.422432Z",
     "start_time": "2025-08-21T18:53:39.265613Z"
    }
   },
   "source": [
    "img = BioImage('./inputs/Experiment-09-test.ome.tiff', reader=bioio_ome_tiff.Reader)\n",
    "print(img.dims)\n",
    "print(img.data.shape)\n",
    "\n",
    "for c in range(img.dims.C):\n",
    "    channel = img.get_image_data('CZYX', C=c)\n",
    "    channel = channel[0, :, :]\n",
    "    print(f'\\n--- Channel {c} ---')\n",
    "    check_bit_depth(channel)\n",
    "    dr = calculate_dynamic_range(channel)\n",
    "    print(f'Dynamic range of Channel {c} is {dr}')\n",
    "    saturation_percentage = calculate_saturation_percentage(channel)\n",
    "    print(f'Relative saturation of Channel {c} is {saturation_percentage}%')\n",
    "    # background_3d, non_uniformity = estimate_background_flat_plane_deviation(channel)\n",
    "    # print(f\"Non-uniformity (Flat Plane Deviation) for Channel {c} is {non_uniformity}\")\n",
    "    zero_bins, zero_bin_ratio = detect_odd_histogram_distribution(channel)\n",
    "    print(f\"Number of zero bins: {zero_bins}\")\n",
    "    print(f\"Ratio of zero bins: {zero_bin_ratio:.4f}\")\n",
    "    for s in range(img.dims.C):\n",
    "        if c == s:\n",
    "            continue\n",
    "        crosstalk = estimate_crosstalk(channel[0], img.get_image_data('CZYX', C=s)[0, 0])\n",
    "        print(f'An estimated {crosstalk * 100:.1f}% of channel {c} is crosstalk from channel {s}')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Dimensions [T: 1, C: 2, Z: 1, Y: 2208, X: 2752]>\n",
      "(1, 2, 1, 2208, 2752)\n",
      "\n",
      "--- Channel 0 ---\n",
      "The image has a bit depth of 16-bits, which is adequate for most purposes.\n",
      "Dynamic range of Channel 0 is 0.2477607385366598\n",
      "Relative saturation of Channel 0 is 0.0%\n",
      "Number of zero bins: 0\n",
      "Ratio of zero bins: 0.0000\n",
      "Using device: cpu\n",
      "An estimated 14.5% of channel 0 is crosstalk from channel 1\n",
      "\n",
      "--- Channel 1 ---\n",
      "The image has a bit depth of 16-bits, which is adequate for most purposes.\n",
      "Dynamic range of Channel 1 is 0.3207904173342489\n",
      "Relative saturation of Channel 1 is 0.0%\n",
      "Number of zero bins: 0\n",
      "Ratio of zero bins: 0.0000\n",
      "Using device: cpu\n",
      "An estimated 42.8% of channel 1 is crosstalk from channel 0\n"
     ]
    }
   ],
   "execution_count": 48
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T18:43:20.203950Z",
     "start_time": "2025-08-21T18:43:20.201874Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
